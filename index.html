<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Jonathan Morgan Final Project</title>
    <link rel="stylesheet" href="styles.css" />
    <link href="prism-correct.css" rel="stylesheet" />
  </head>
  <body>
    <div id="container">
      <div id="header">
        <h1>An Evaluation of Shootings in the United States</h1>
        <h3>Jonathan Morgan</h3>
        <h3>Spring 2024 Data Science Project</h3>
        <h4>Member 1(and only): Jonathan Morgan, Contribution: 100% (did to everything).</h4>
        <p>I did everything in the project, all html/css and colab/coding</p>
      </div>
      <hr />
      <div id="intro">
        <h2>Introduction:</h2>
        <p>
          Over the past decade shootings have only increased. This has become a
          very big issue in the United States, and has had a profound impact on
          many individuals and the country as a whole. There are many different
          opinions on what a proper solution is, such as banning guns
          completelty, investing into more extensive background checks, or
          putting more focus on mental health. While a solution is being argued
          over, shootings still occur regularly with no change. In this project
          I am not seeking a solution, but instead seeking to find valuable
          insights and trends regarding what qualities are common among most
          active shooters, race, genger, mental health, etc. This data will
          assist in finding a solution because it provides valuable information
          about what exactly “makes” an active shooter. Knowing this can help
          pinpoint which direction a possible solution to this issue should
          point.
        </p>
        <br />
        <b>Sections:</b>
        <ol>
          <li><a href="#intro">Introduction</a></li>
          <li><a href="#data-curation">Data Curation</a></li>
          <li><a href="#data-analysis">Exploratory Data Analysis</a></li>
          <li><a href="#primary-analysis">Primary Analysis</a></li>
          <li><a href="#visualization">Visualization</a></li>
          <li><a href="#conclusion">Insights and Conclusion</a></li>
        </ol>
      </div>
      <hr />
      <div id="data-curation">
        <h2>Data Curation:</h2>
        <p>
          We will be using <b>Google Colab</b> for this tutorial. It is provides
          use with free acces to computing resources that are well suited for
          data science and machine learning. Follow
          <a href="https://colab.research.google.com/" target="”_blank”"
            >this</a
          >
          link to learn more about the service if you don't, or to get a feel
          for the UI and tools before continuing. Once you've done that create a
          new Colab and name it whatever you'd like.
        </p>
        <p>
          These are all the imports we will be using in this tutorial, add them
          to your Colab and run the cell:
        </p>
        <pre class="line-numbers">
            <code class="language-python">
                ! pip install scikit-posthocs

                import scikit_posthocs as sp
                from sklearn.datasets import load_iris
                import pandas as pd
                import matplotlib.pyplot as plt
                import numpy as np 
                from scipy.stats import chi2_contingency
                from scipy.stats import mannwhitneyu
                from scipy.stats import kruskal
                import statsmodels.api as sm
                from scipy import stats
                from sklearn.preprocessing import StandardScaler
                from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
                from sklearn.preprocessing import StandardScaler
                from sklearn.tree import DecisionTreeClassifier
                from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
                
            </code>
          </pre>
        <hr class="hr" />
        <h3>Gathering Data:</h3>
        <p>
          First we need to gather data shootings in the United States. This data
          needs to contain a decent amount of information about the shooting as
          well as the shooter so that we can have more data to work with later
          on. I was able to find pretty good data set on Kaggle that contains
          data on US shootings for the past 50 years. Follow
          <a
            target="”_blank”"
            href="https://www.kaggle.com/datasets/zusmani/us-mass-shootings-last-50-years/data"
            >this</a
          >
          link to download the data and add it to your Colab. We specifically
          only want Dataset Ver 5, so only include that one.
        </p>
        <p>
          After you've done that we need to run the following in order to create
          a dataframe with our csv file:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            mass_shootings_5 = pd.read_csv('Mass Shootings Dataset Ver 5.csv', encoding='cp1252')
          </code>
        </pre>
        <p>
          If you run
          <code class="language-python">mass_shootings_5.head(10)</code> your
          data frame should look like this:
        </p>
        <img src="imgs/unformatted-df.jpg" />
        <p>
          There are many columns that we don't need or want because they don't
          have enough entries or because they aren't useful to us. Execute the
          following in order to get rid of them:
        </p>

        <code class="language-python">
          mass_shootings_5 = mass_shootings_5.drop(columns=['Title', 'S#',
          'Incident Area', 'Summary', 'Fatalities', 'Injured', 'Age', 'Employeed
          (Y/N)', 'Employed at', 'Latitude', 'Longitude'])</code
        >
        <p>
          Now we need to edit some of our columns because the data in them isn't
          properly formatted. The "location" column includes the city, which we
          don't really care for, so we need remove it, and the "target" and
          "cause" columns vary too much in their categories so we need to
          condense them into more broad categories.
        </p>
        <p>In order to do this I have created the following three functions:</p>
        <pre class="line-numbers">
          <code class="language-python">
            def remove_city(location):
  if str(location) != 'nan':
    splitted_loc = location.split()
    if splitted_loc[-2] in ['New', 'North', 'Rhode', 'South', 'West']:
      state = splitted_loc[-2] + ' ' + splitted_loc[-1]
    else:
      state = splitted_loc[-1]
    return state

def fix_target(target):
  target = str(target).lower()

  if target != 'nan':
    if ('ex-' in target):
      target = 'Ex-Person(s)'
    elif (('teacher' in target) | ('student' in target) | ('teachers' in target) | ('students' in target) | ('school' in target)):
      target = 'School'
    elif ('child' in target):
      target = 'Children'
    elif (('congress' in target) | ('police' in target) | ('council' in target) | ('social worker' in target) | ('tsa' in target) | ('marine' in target)):
      target = 'Government Employee(s)'
    elif (('coworker' in target) | ('friend' in target) | ('neighbor' in target) | ('guest' in target) | ('employee' in target)):
      target = 'Relationship (non-familial)'
    elif ('family' in target):
      target = 'Family'
    elif ('random' in target):
      target = 'Random'
    elif ('women' in target):
      target = 'Women'
    elif (('black' in target) | ('white' in target) | ('sikhs' in target) | ('monk' in  target) | ('pray' in target)):
      target = 'Race/Religion'
    else:
      target = 'Other'

    return target

def fix_cause(cause):
  cause = str(cause).lower()

  if ('frustration' == cause):
    cause = 'anger'
  elif ('nan' == cause):
    cause = 'unknown'
  elif (('domestic' in cause) | ('breakup' == cause)):
    cause = 'domestic'
  elif (('exam' in cause) | ('suspension' == cause)):
    cause = 'school'

  return cause
          </code>
        </pre>
        <p>
          Add these functions to your collab and run the following in order to
          fix the columns:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            mass_shootings_5['Location'] = mass_shootings_5['Location'].apply(remove_city)
            mass_shootings_5['Target'] = mass_shootings_5['Target'].apply(fix_target)
            mass_shootings_5['Cause'] = mass_shootings_5['Cause'].apply(fix_cause)
          </code>
        </pre>
        <p>
          There are some more issues with "Location" column that we need to fix.
          We've gotten rid of the city, but the state is inconsistent. Sometimes
          it is abbreviated, and sometimes it is not. We need this to be
          consistent, so we are going to replace the abbreviations.
        </p>
        <p>In order to do this, use the following dictionary:</p>
        <pre class="line-numbers">
          <code class="language-python">
            states = {
              'AK': 'Alaska','AL': 'Alabama','AR': 'Arkansas','AZ': 'Arizona','CA': 'California',
              'CO': 'Colorado','CT': 'Connecticut','DC': 'District of Columbia','DE': 'Delaware','FL': 'Florida',
              'GA': 'Georgia','HI': 'Hawaii','IA': 'Iowa','ID': 'Idaho','IL': 'Illinois',
              'IN': 'Indiana','KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana','MA': 'Massachusetts',
              'MD': 'Maryland','ME': 'Maine','MI': 'Michigan','MN': 'Minnesota','MO': 'Missouri',
              'MS': 'Mississippi','MT': 'Montana','NC': 'North Carolina','ND': 'North Dakota','NE': 'Nebraska',
              'NH': 'New Hampshire','NJ': 'New Jersey','NM': 'New Mexico','NV': 'Nevada','NY': 'New York',
              'OH': 'Ohio','OK': 'Oklahoma','OR': 'Oregon','PA': 'Pennsylvania','RI': 'Rhode Island',
              'SC': 'South Carolina','SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas','UT': 'Utah',
              'VA': 'Virginia','VT': 'Vermont','WA': 'Washington','WI': 'Wisconsin','WV': 'West Virginia',
              'WY': 'Wyoming','PR': 'Puerto Rico','VI': 'Virigin Islands', 'D.C.': 'District of Columbia'
              }
          </code>
        </pre>
        <p>And run this:</p>
        <code class="language-python">
          mass_shootings_5['Location'] =
          mass_shootings_5['Location'].replace(states)</code
        >
        <p>Now as a final touch we will rename the "Total victims" column:</p>
        <code class="language-python">
          us_mass_shootings = mass_shootings_5.rename(columns={'Total victims':
          'Total Victims'})</code
        >
        <p>
          Now if you run
          <code class="language-python">mass_shootings_5.head(10)</code> again,
          it should look like:
        </p>
        <img src="imgs/formatted-df.jpg" alt="" />
      </div>
      <hr />
      <div id="data-analysis">
        <h2>Data Analysis:</h2>
        <p>
          In this section we want to learn more about the data. So are there any
          correlations, trends, or insights that we can find? With this new
          information we can better set up our primary analysis. Since I want to
          be able to find relationships between our columns, most of our
          analysis here will be trying to see if any of our features correlates
          with one another. We will do this through the use of multiple
          techniques that will provide some valuable insights.
        </p>
        <hr class="hr" />
        <h3>The Target and Presence of Mental Health Issues</h3>
        <p>
          Here we are going to see if there is any correlation between the
          target of a shooting, and whether or not the shooter has some kind of
          mental health issue. In order to do this we will use chi-squared test.
        </p>
        <p>
          Chi-Squared test are used to check if two categorical variables come
          from the same distribution. This means that we should be able to see
          if there is some kind of relationship between the two features. If you
          want to learn more about chi-squared question click
          <a
            href="https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests"
            >here</a
          >
        </p>
        <p>
          First lets define our null and alternative hypothesis. The null
          hypothesis (H<sub>0</sub>) is what we are trying to disprove and the
          alternative hypothesis (H<sub>A</sub>) is what we are trying to prove.
        </p>
        <ul>
          <li>
            <b>H<sub>0</sub></b
            >: The mental health of a shooter has an effect on the target of a
            mass shooting.
          </li>
          <li>
            <b>H<sub>A</sub></b
            >: The mental health of a shooter does have an effect on the target
            of a mass shooting.
          </li>
        </ul>
        <p>
          In order to effectively use this test we will put our data in a
          contingency table. Contingency tables place one variable on one exis,
          and another variable on the other. This format allows relationships
          between the data to be more identifiable. Click
          <a href="https://en.wikipedia.org/wiki/Contingency_table">here</a> to
          learn more about contingency tables.
        </p>
        <p>Run this in order to create our table:</p>
        <pre class="line-numbers">
          <code class="language-python">
            new_df = us_mass_shootings[(us_mass_shootings['Mental Health Issues'] == 'Yes') | (us_mass_shootings['Mental Health Issues'] == 'No')]
            contingency_table = pd.crosstab(new_df['Target'], new_df['Mental Health Issues'])
          </code>
        </pre>
        <p>
          If you now display the table with
          <code class="language-python">contingency_table</code>, then it should
          look like this:
        </p>
        <img style="height: 25rem" src="imgs/contingency_table.jpg" />
        <p>
          Before we figure out whether or not we can prove there is some
          relationship, let's visualize the data with a bar graph. To do this,
          use the following code:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            plot = contingency_table.plot(kind='bar', title='Relationship Between Target and Mental Health Issues')
            plot.set_xlabel("Target of Shooting")
            plot.set_ylabel("# of Shootings With/Without Mental Health Issues")
          </code>
        </pre>
        <p>This should display the following graph:</p>
        <img style="height: 40rem" src="imgs/contingency_plot.png" />
        <p>
          From this graph we can see that certain target such as "Random",
          "School", and "Ex-Person(s)" have a much higher number of shootings
          that involve mental health issues. While other targets, "Family" and
          "Relationship (non-familial)", have a higher rate of shootings that
          don't involve mental health issues. Although there is evidence of
          higher and lower occurences depending on the target based on this
          graph, it is not enough for us to conclude that there is some
          relationship. So, we must use the chi-squared test.
        </p>
        <p>To run Chi-Squared test run the following code:</p>
        <code class="language-python">
          chi2, p_value, dof, ex = chi2_contingency(contingency_table)</code
        >
        <p>
          Now if you display the p_value by running
          <code class="language-python">p_value</code>, then
          <code>0.48715665898535343</code>
          will be displayed
        </p>
        <p>
          What does this value mean? The p value is essential how confident we
          are that we can reject the null hypothesis. It's actually more like
          the probability that the alternative hypothesis is just a coincidence
          or error, but I feel like my previous definition is slightly easier to
          understand. We want this value be below .05 (<a
            href="https://resources.nu.edu/statsresources/alphabeta#:~:text=Alpha%20is%20also%20known%20as,being%20compared%20to%2C%20for%20example."
            >alpha value</a
          >), which means we are highly confident in rejecting the null
          hypothesis. To learn more about p-values click the
          <a
            href="https://www.investopedia.com/terms/p/p-value.asp#:~:text=A%20p%2Dvalue%20is%20a%20statistical%20measurement%20used%20to%20validate,significance%20of%20the%20observed%20difference."
            >here</a
          >.
        </p>
        <p>
          Since it isn't below .05 we fail to reject our null hypothesis, so we
          can't definitevily say that there is a connection between the two
          features based on this. So, there is no direct relation between the
          target and if the shooter has mental health issues.
        </p>
        <hr class="hr" />
        <h3>The Location and Number of Injuries</h3>
        <p>
          Next we are going to see if there is a relationship between the number
          of injuries and whether or not the shooting took place in an open or
          closed location. A closed location are places that are usually
          indoors, like a mall, or building, and an open location is usually
          outdoors, so a beach or parking lot.
        </p>
        <p>
          In order to do this, we are going to use a Mann-Whitney U test. This
          is because the two features are independent from eachother and not
          normally distributed. This is once again a good test to use when you
          want to compare two features. To learn more about Mann-Whitney U test,
          click
          <a
            href="https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/mann-whitney-u-test/#:~:text=Mann%2DWhitney%20U%20test%20is,means%20are%20equal%20or%20not."
            >here</a
          >
        </p>
        <p>
          Once again we are going to define our null and alternative hpothesis:
        </p>
        <ul>
          <li>
            <b>H<sub>0</sub></b
            >: The location being opened or closed has no affect on the amount
            of injuries.
          </li>
          <li>
            <b>H<sub>A</sub></b
            >: The location being opened or closed has an affect on the amount
            of injuries.
          </li>
        </ul>
        <p>
          Before doing the test though lets try and visualize the relationship
          with the use of a box plot. We'll start by seperating the opened and
          closed data:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
          open_location = us_mass_shootings[us_mass_shootings['Open/Close Location'] == 'Open']['Total Victims'] 
          closed_location =us_mass_shootings[us_mass_shootings['Open/Close Location'] == 'Close']['Total Victims']
          </code>
        </pre>
        <p>We can now create the box plot with the following:</p>
        <pre class="line-numbers">
          <code class="language-python">
            plt.xlabel('Open/Close Location')
            plt.ylabel('Total Victims')
            plt.title('Boxplot of Total Victims by Open/Close Location')
            plt.boxplot([us_mass_shootings[us_mass_shootings['Open/Close Location'] == 'Open']['Total Victims'], us_mass_shootings[us_mass_shootings['Open/Close Location'] == 'Close']['Total Victims']],
                        labels=['Open', 'Closed'])
            
            plt.show()
          </code>
        </pre>
        <p>This is the box plot we get:</p>
        <img style="height: 25rem" src="imgs/zoomedOut-boxplt.jpg" />
        <p>
          From this we can really see anything because there are some pretty
          high outliers which are affecting the distribution of the data, but
          can zoom in a little bit so that I can actually see the box plots with
          the following:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            plt.boxplot([us_mass_shootings[us_mass_shootings['Open/Close Location'] == 'Open']['Total Victims'], us_mass_shootings[us_mass_shootings['Open/Close Location'] == 'Close']['Total Victims']],
            labels=['Open', 'Closed'])
            plt.xlabel('Open/Close Location')
            plt.ylabel('Total Victims')
            plt.title('Boxplot of Total Victims by Open/Close Location')
            plt.ylim(0,50)
            plt.show()
          </code>
        </pre>
        <p>Our plot now looks like this:</p>
        <img style="height: 25rem" src="imgs/zoomedIn-boxplt.jpg" alt="" />
        <p>
          We can see the actual data in the box plots much better now. In the
          plots we can see that they both are right skewed, so on average both
          open and closed locations are greater than their medians. The open
          location box plot is most likely more skewed because it has much
          higher outliers than the closed location. The outliers in this dataset
          may cause us some problems, so it is something we should look out for
          if need be in later sections.
        </p>
        <p>
          Now lets find our p-value so that we can see if we can reject or fail
          to reject our null hypothesis (alpha value is once again .05). To do
          this, run the following:
        </p>
        <code class="language-python"
          >statistic, p_value = mannwhitneyu(open_location, closed_location)
        </code>
        <p>
          If we display the p-value by running
          <code class="language-python">p_value</code>, we get
          <code>0.03603286133592586.</code>
        </p>
        <p>
          Our p-value is less than the alpha (.05) so we reject the null
          hypothesis. This means that there is some relationship between whether
          the location is opened or closed and the amount of victims harmed. We
          can explore this more in the Machine Learning section, and use this to
          help our analysis.
        </p>
        <hr class="hr" />
        <h3>Causes and the Number of Victims</h3>
        <p>
          For this analysis we want to compare the causes to the number of
          victims in a shooting. We also want to see how those causes compare to
          each other in realtion to the number of victims that they have. The
          causes are basically the reason why the shooter commited the crime. So
          things like "anger", "revenge", "domestic" disputes, etc.
        </p>
        <p>
          We will do this with the use of an ANOVA test. We use ANOVA test in
          order to compare different groups in order to see if there are any
          significant differences. To learn more about ANOVA test, click
          <a
            href="https://www.investopedia.com/terms/a/anova.asp#:~:text=Key%20Takeaways-,Analysis%20of%20variance%20(ANOVA)%20is%20a%20statistical%20test%20used%20to,ANOVA%20uses%20two%20independent%20variables."
            >here</a
          >.
        </p>
        <p>
          Before we do our test, lets visualize our data with a bar graph that
          compares the average amount of victims in each cause along with the
          overall average. First we need to create a dataframe with all of our
          averages:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            averages = us_mass_shootings.groupby('Cause').agg({'Total Victims': 'mean'}).reset_index()
            averages.columns = ['Cause', 'Average Total Victims']
          </code>
        </pre>
        <p>It should look like this:</p>
        <img style="height: 20rem" src="imgs/causes_averages.jpg" alt="" />
        <p>
          Now we want the overall mean between the categories, we can do that by
          runnning this:
        </p>
        <code class="language-python"
          >causes_mean = averages['Average Total Victims'].mean()
        </code>
        <p>
          Finally, lets display our create and display our bar graph by running
          the following:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            plot = averages.plot.bar(x='Cause', y='Average Total Victims')
            plt.axhline(y=causes_mean, color='r', linestyle='-')
            plt.ylabel('Average Total Victims')
            plot
          </code>
        </pre>
        <p>Our plot should look like this:</p>
        <img style="height: 30rem" src="imgs/causes_avgs_plt.png" alt="" />
        <p>
          With this bar graph we can see the relationship between the different
          causes and how they differ from each other when it comes to the
          average amount of victims harmed. There are definetly some causes that
          seem to cause much more harm than others, but we should use our ANOVA
          test in order to be sure.
        </p>
        <p>
          For our ANOVA test, we also need to define a null and alternative
          hypothesis:
        </p>
        <ul>
          <li>
            <b>H<sub>0</sub></b
            >: The means will be the same accross all groups, so the cause has
            no affect on total victims.
          </li>
          <li>
            <b>H<sub>A</sub></b
            >: The means won't be the same accross all groups, so the cause has
            an affect on total victims.
          </li>
        </ul>
        <p>
          Before we do our ANOVA test, we must ensure that all of our groups is
          normally distributed, we can check anger by graphing it like so:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            dist = us_mass_shootings[us_mass_shootings['Cause'] == 'anger']['Total Victims']
            sm.qqplot(dist)
          </code>
        </pre>
        <p>The graph should look like this:</p>
        <img style="height: 25rem" src="imgs/anova-dist.jpg" alt="" />
        <p>
          As we can see this isn't normally distributed, so we can't use an
          ANOVA test, but we can use something similar called a Kruskal-Wallis
          test. It's accomplishes the same, but without the need for normally
          distributed data. You can learn more about Kruskal-Wallis test
          <a
            href="https://www.technologynetworks.com/informatics/articles/the-kruskal-wallis-test-370025#:~:text=The%20Kruskal%E2%80%93Wallis%20test%20is%20a%20statistical%20test%20used%20to,analysis%20of%20variance%20(ANOVA)."
            >here</a
          >.
        </p>
        <p>
          We can run the test and obtain our p-value by doing the following:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            anger = us_mass_shootings[us_mass_shootings['Cause'] == 'anger']['Total Victims']
            unemployement = us_mass_shootings[us_mass_shootings['Cause'] == 'unemployement']['Total Victims']
            racism = us_mass_shootings[us_mass_shootings['Cause'] == 'racism']['Total Victims']
            domestic =us_mass_shootings[us_mass_shootings['Cause'] == 'domestic']['Total Victims']
            pyscho = us_mass_shootings[us_mass_shootings['Cause'] == 'psycho']['Total Victims']
            revenge = us_mass_shootings[us_mass_shootings['Cause'] == 'revenge']['Total Victims']
            school = us_mass_shootings[us_mass_shootings['Cause'] == 'school']['Total Victims']
            religious_radicalism = us_mass_shootings[us_mass_shootings['Cause'] == 'religious radicalism']['Total Victims']
            drunk = us_mass_shootings[us_mass_shootings['Cause'] == 'drunk']['Total Victims']
            robbery = us_mass_shootings[us_mass_shootings['Cause'] == 'robbery']['Total Victims']
            unknown = us_mass_shootings[us_mass_shootings['Cause'] == 'unknown']['Total Victims']
            terrorism = us_mass_shootings[us_mass_shootings['Cause'] == 'terrorism']['Total Victims']
            
            stat, p_value = kruskal(anger, unemployement, racism, domestic, pyscho, revenge, school, religious_radicalism, drunk, robbery, unknown, terrorism)
          </code>
        </pre>
        <p>
          If you display the p-value with
          <code class="language-python">p_value</code>, then we get
          <code>2.1963291386413655e-05 </code>
        </p>
        <p>
          Our alpha value is still .05, so this is significantly below that,
          which means that we can reject our null hypothesis. This means that
          there are differences between the causes in relation to the total
          number of victims. So some causes like "terrorism" would have a higher
          total victim count than "domestic" disputes.
        </p>
        <p>
          We can confirm the significant differences between the groups with a
          post-hoc test. This will basically give us the actual comparison
          between groups so we can see just how different they are. If you want
          to learn more about post-hoc test, click
          <a
            href="https://www.cwauthors.com/article/significance-and-use-of-post-hoc-analysis-studies#:~:text=Post%20hoc%20in%20Latin%20means,also%20called%20multiple%20comparison%20tests."
            >here</a
          >.
        </p>
        <p>The following code will create the results for our post-hoc test:</p>
        <pre class="line-numbers">
          <code class="language-python">
            data = pd.DataFrame({
              'anger': anger.dropna(),
              'unemployment': unemployement.dropna(),
              'racism': racism.dropna(),
              'domestic': domestic.dropna(),
              'psycho': pyscho.dropna(),
              'revenge': revenge.dropna(),
              'school': school.dropna(),
              'religious_radicalism': religious_radicalism.dropna(),
              'drunk': drunk.dropna(),
              'robbery': robbery.dropna(),
              'unknown': unknown.dropna(),
              'terrorism': terrorism.dropna()
          })
          
          data = data.apply(lambda x: x.fillna(x.mean()))
          data = data.melt(var_name='Cause', value_name='Total Victims').dropna()
          results = sp.posthoc_dunn(data, val_col='Total Victims', group_col='Cause', p_adjust='bonferroni')
          </code>
        </pre>
        <p>
          Now we can display results with
          <code class="language-python">results</code> which would give us a
          kind of matrix with the p-values of each comparison. Instead of just
          displaying that we will make it slightly easier to understand by
          replacing the p-values with True and False. True if the p-value is
          greater than .05, meaning that there is a significant difference, and
          false if otherwise, meaning there isn't a significant difference.
          Doing this is simple, just run the following:
        </p>
        <code class="language-python">resultsTF = results < .05 </code>
        <p>
          If you display the new dataframe with
          <code class="language-python">resultsTF</code>, then your output
          should look something like this:
        </p>
        <img src="imgs/post_hoc_results.jpg" alt="" />
        <p>
          From this you can see that a lot of our data has a significant
          difference between features. This means that there is a meaningful
          distinciton between the cause and the amount of victims for a lot of
          our categories. This means that the cause does cause some difference
          in the amount of victims resulting from the shooting, and here we can
          see which causes actually have that difference.
        </p>
        <hr class="hr" />
        <h3>Analysis Conclusion</h3>
        <p>
          After this analysis we can see that a lot of our data is categorical,
          and we were able to point out some relationships between those
          categories. From our final analysis we can seethat the cause does have
          an effect on the number of total victims. We were also able to gather
          from out second analysis that the location being open or closed had an
          effect on the number of victims, with open locations having slightly
          more. In thenext section we will use these insights in order to
          determine what kind of machine learning analysis and function we will
          use.
        </p>
      </div>
      <hr />
      <div id="primary-analysis">
        <h2>Machine Learning:</h2>
        <p>
          Since we have collected, cleaned, and gained insights from our data,
          we will now develop a Machine Learning model that shows how some of
          our features contribute to how deadly a shooting can be. This will
          enable us to figure out what features are correlated higher victim
          totals. To do this we will use some machine learning techniques.
        </p>
        <hr class="hr" />
        <h3>Creating our Model</h3>
        <p>
          In the previous section we were able to see that the Total Victims
          feature can be affected by the cause and whether or not the location
          is opened or closed. So we will mostly focus on that in this section.
        </p>
        <p>
          This means that our independent variables will be our other features,
          not Total Victims, and the dependent variable will be the Total
          Victims.
        </p>
        <p>
          First we have to decide what Machine Learning. Since we want to
          predict a real valued continous feature, we should select some kind of
          regression model. I think that a Decision Tree would be our best bet
          because of the nature of our data, and what we want to do with it.
          Given some categorical data we want to make a decision/estimate about
          how many possible Victims could be in a shooting. A decision tree
          seems best to accomplish this goal. To learn more about decision
          trees, click
          <a
            href="https://www.lucidchart.com/pages/decision-tree#:~:text=A%20decision%20tree%20is%20a,costs%2C%20probabilities%2C%20and%20benefits."
            >here</a
          >.
        </p>
        <p>
          First we need to split out data, and handle outliers. To do that we're
          just going to exclude them:
        </p>
        <pre class="line-numbers">
          <code class="'language-python">
            data = us_mass_shootings.drop(columns=['Location', 'Date','Gender', 'Race', 'Target'], axis = 1)
            # Z-score for each value in the column
            z_scores = stats.zscore(data['Total Victims'])
            
            # threshold for the Z-score
            threshold = 2
            
            # Filter rows
            data = data[abs(z_scores) < threshold].dropna()
            
            data_x = data.drop('Total Victims', axis=1)
            data_y = data['Total Victims']
          </code>
        </pre>
        <p>
          Now we are going to encode our data as well as create our training and
          testing data. We need to encode the data because all of our other
          features are categorical. We won't be able to properly train our
          models with those, so we need to encode them. To learn more about what
          exactly encoding is, click
          <a
            href="https://medium.com/anolytics/all-you-need-to-know-about-encoding-techniques-b3a0af68338b#:~:text=Encoding%20categorical%20variables%20is%20a,compatibility%20with%20machine%20learning%20algorithms."
            >here</a
          >.
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            data_x_encoded = pd.get_dummies(data_x, drop_first=True)
            X_train, X_test, y_train, y_test = train_test_split(data_x_encoded, data_y, test_size=0.3, random_state=42)
          </code>
        </pre>
        <p>
          Next we'll define our model, and perform
          <a
            href="https://www.analyticsvidhya.com/blog/2022/02/k-fold-cross-validation-technique-and-its-essentials/#:~:text=K%2Dfold%20cross%2Dvalidation%20is,estimate%20the%20model's%20generalization%20performance."
            >k-fold validation</a
          >
          to help evaluate our the model.
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            model = DecisionTreeClassifier()
            k_folds = 5
            skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
            score = cross_val_score(model, X_train, np.ravel(y_train), cv=skf)
            print("Decision Tree: " + str(score.mean()) + " ( +/- " + str(score.std()) + ")")
          </code>
        </pre>
        <p>
          Based on our output, we can see that our performance isn't very good,
          <code>.23500000000000001</code>, lets try some other models to see if
          they do any better:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            models = {'KNN': KNeighborsClassifier(),
            'DecisionTree': DecisionTreeClassifier(),
            'LogisticRegression': LogisticRegression(max_iter=1000),
            'RandomForest': RandomForestClassifier()}

            k_folds = 5
            skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
            for model_name, model in models.items():
              score = cross_val_score(model, X_train, np.ravel(y_train), cv=skf)
              print(model_name + ": " + str(score.mean()) + " ( +/- " + str(score.std()) + ")")
          </code>
        </pre>
        <p>
          The output of these other models are even worse, so lets stick with
          the decision tree and see if we can improve its performance.
        </p>
        <hr class="hr" />
        <h3>Training our Model</h3>
        <p>
          Now we have to use our training and test data in order to train and
          evaluate our model. In order evaulate our model we will take a look at
          its
          <a
            href="https://medium.com/@kohlishivam5522/understanding-a-classification-report-for-your-machine-learning-model-88815e2ce397"
            >classification report</a
          >.
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            # Train Model
            model.fit(std_X_train, np.ravel(y_train))

            # Evaluate performance
            y_pred = model.predict(std_X_test)
            accuracy = accuracy_score(y_pred, y_test)
          
            print("Accuracy of "+model_name+": "+str(accuracy))
            print('Classification Report: ')
            print(classification_report(y_test, y_pred, zero_division=1))
          </code>
        </pre>
        <p>This is our output:</p>
        <img style="height: 30rem" src="imgs/class_report.jpg" alt="" />
        <p>
          From this we can see that our model isn't the greatest, but it is very
          <a
            href="https://c3.ai/glossary/machine-learning/precision/#:~:text=Precision%20is%20one%20indicator%20of,the%20number%20of%20false%20positives)."
            >precise</a
          >. Especially when it comes to higher Victim Counts.
        </p>
        <hr class="hr" />
        <h3>Fine Tuning Our Model</h3>
        <p>
          Since our models performance wasn't very good, lets try to improve it
          via fine tuning. The following code should help fine tune our decision
          tree and improve performance:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            for criterion in ['gini', 'entropy']:
              for max_depth in [2,3,4,5,6]:
                  for min_samples_leaf in [5, 10, 20, 30]:
                      model = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, min_samples_leaf=min_samples_leaf)
                      model.fit(X_train, y_train)
                      test_predictions = model.predict(X_test)
                      test_acc = accuracy_score(y_test, test_predictions)
                      if test_acc > best_acc:
                          best_acc = test_acc
        
            print(best_acc)
          </code>
        </pre>
        <p>
          Out performance still isn't great,
          <code>0.29545454545454547 </code> but is better than it was before, so
          we'll stick with it for now.
        </p>
        <p>
          Lets take a look at our classifcation report again to see if anything
          else improved:
        </p>
        <pre class="line-numbers">
          <code class="language-python">
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_pred, y_test)
            
            print("Accuracy of Model: "+str(accuracy))
            print('Classification Report: ')
            print(classification_report(y_test, y_pred, zero_division=1))
          </code>
        </pre>
        <p>Output:</p>
        <img style="height: 30rem" src="imgs/tuned_report.jpg" alt="" />
        <p>
          As you can see it's mostly the same, but our precision did improve a
          decent amount. The higher precision levels, especially with some
          larger Victim Totals could be attributed to those kinds of shootings
          being more rare, making them easier to predict that the more average
          victim totals.
        </p>
      </div>
      <hr />
      <div id="visualization">
        <h2>Visualization</h2>
        <p>
          Lets plot our decision tree to see what it looks like. This is one of
          the benefits of a decision tree, it is fairly simple to look at and
          understand since it works in a similar(ish) way to the human brain.
          Looking at a Decision Tree can help us understand what the "thought"
          process is like for the model.
        </p>
        <p>The following code will display the model:</p>
        <pre class="line-numbers">
          <code class="language-python">
            fig = plt.figure(figsize=((25,20)))
            plot_tree(model, 
                        feature_names = data_x_encoded.columns,
                        impurity=False,
                        proportion=True,
                        filled=True)
          </code>
        </pre>
        <p>Output:</p>
        <img src="imgs/DTree.png" alt="" />
        <p>
          This visualization provides some insights into how the tree makes its
          decisions. We can see here how it decided to split the features. Which
          is very important when building a decision tree. This is very
          important because the split depends on the level of entropy resulting
          from it. Based off of the first split with Mental Health issues, we
          can tell that the tree is pretty confident in classifying the total
          victims based on just that category. When it comes to unknown mental
          health issues the tree seems to need to also check the open/close
          location feature before making a decision.
        </p>
        <p>
          This transparency that comes with decision trees is very valuable
          since it has alowed us to gain some more insights into the decision
          mkaing/classification proccess.
        </p>
      </div>
      <hr />
      <div id="conclusion">
        <h2>Conclusion</h2>
        <p>
          Although we weren't able to pinpoint a solution as much as I hoped,
          there were some valuable insights that I believe we about shootings:
        </p>
        <ol>
          <li>
            We were able to indentify a relationship between whether the
            location is opened or closed and the amount of victims harmed.
          </li>
          <li>
            We were able to indentify a meaningful distinciton between the cause
            and the amount of victims for a lot of our categories.
          </li>
        </ol>
        <p>
          With these insights we developed were able to Machine Learning Model,
          which although not working very well, was able to still give some
          valuable experience and information about that step in the data
          science proccess.
        </p>
        <p>
          We are still a long road away from a solid solution to this issue that
          plagues the US, but through the use of more data science techniques
          and tools, a possible solution could be found much quicker.
        </p>
      </div>
    </div>
    <script src="prism-correct.js"></script>
  </body>
</html>
